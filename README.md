# awesome-hallucination-fact-checking-in-NLG
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/hee9joon/Awesome-Diffusion-Models) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Made With Love](https://img.shields.io/badge/Made%20With-Love-red.svg)](https://github.com/chetanraj/awesome-github-badges)

This repository contains a collection of resources and papers on ***Hallucination & Fact-Checking-in-NLG***.

## Contents
- [Resources](#resources)
  - [Introductory Posts](#introductory-posts)
  - [Introductory Videos](#introductory-videos)
  - [Introductory Lectures](#introductory-lectures)
  - [Tutorial and Jupyter Notebook](#tutorial-and-jupyter-notebook)
- [Papers](#papers)
  - [Survey](#survey)


# Resources
## Introductory Posts
**GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses.** \
*OpenAI* \
[[Website](https://openai.com/product/gpt-4)] \
14 Mar 2023

## Dataset & Benchmarks

**TruthfulQA: Measuring How Models Mimic Human Falsehoods** \
*Stephanie C. Lin, Jacob Hilton, Owain Evans* \

**FaithDial: A Faithful Benchmark for Information-Seeking Dialogue**
*Nouha Dziri, Ehsan Kamalloo, Sivan Milton, Osmar Zaiane, Mo Yu, Edoardo M. Ponti, Siva Reddy*
TACL 2022 [[Paper](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00529/114373/FaithDial-A-Faithful-Benchmark-for-Information)]


# Papers 

## Survey

**A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity** \
*Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung* \
28 Feb 2023. [[Paper](https://arxiv.org/abs/2302.04023)] 

**Augmented Language Models: a Survey**
*Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, Thomas Scialom*
15 Feb 2023 [[Paper](https://arxiv.org/abs/2302.07842)]

**Automated fact-checking for assisting human fact-checkers**
*Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed, Alberto Barrón-Cedeño, Paolo Papotti, Shaden Shaar, Giovanni Da San Martino*
13 Mar 2021 [[Paper](https://arxiv.org/abs/2103.07769)]

**Survey of hallucination in natural language generation**

## Domains
### Commensense

### Professional Knowledge
**Training Verifiers to Solve Math Word Problems** \
*Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman* \
OpenAI Otc 2021 [[Paper](https://arxiv.org/abs/2110.14168)]

**Self-Consistency Improves Chain of Thought Reasoning in Language Models** \
*Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou* \
ICLR 2023 [[Paper](https://arxiv.org/abs/2203.11171)]

**Least-to-most prompting enables complex reasoning in large language models** \
*Jing Qian, Hong Wang, Zekun Li, Shiyang Li, Xifeng Yan* \
[[Paper]()]

**Limitations of language models in arithmetic and symbolic induction** \
*Jing Qian, Hong Wang, Zekun Li, Shiyang Li, Xifeng Yan* \
Aug 2022 [[Paper](https://arxiv.org/abs/2208.05051)]

**Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs
*Albert Q. Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, Guillaume Lample* \
ICLR 2023 [[Paper](https://arxiv.org/abs/2210.12283)]

**Can large language models reason about medical questions?** \
*Valentin Liévin, Christoffer Egeberg Hother, Ole Winther* \
Jan 2023 [[Paper](https://arxiv.org/abs/2207.08143)]

**Large Language Models Encode Clinical Knowledge** \
*Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli, Aakanksha Chowdhery, Philip Mansfield, Blaise Aguera y Arcas, Dale Webster, Greg S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, Vivek Natarajan* \
Google Research & OpenAI [[Paper](https://arxiv.org/abs/2212.13138)]

**ChemCrow: Augmenting large-language models with chemistry tools** \
*Andres M Bran, Sam Cox, Andrew D White, Philippe Schwaller* \
April 2023 [[Paper](https://arxiv.org/abs/2304.05376)]


**PAL: Program-aided Language Models** \
*Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig* \
Jan 2023 [[Paper](https://arxiv.org/abs/2211.10435)]

**Evaluating Large Language Models Trained on Code** \
*Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba* \
OpenAI 2021 [[Paper](https://arxiv.org/abs/2107.03374)]

### External Knowledge Base



## Causal Analysis


## Learn to say no & Out-of-distribution & Uncertainty Estimation && Calibration 
**Out-of-Distribution Detection and Selective Generation for Conditional Language Models**\ 
*Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, Peter J Liu*\
ICLR 2023 [[Paper](https://openreview.net/forum?id=kJUS5nD0vPB)] 

**Language Models (Mostly) Know What They Know** \
*Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, Jared Kaplan* \
Nov 2023 [[Paper](https://arxiv.org/abs/2207.05221)]

**How can we know when language models know? on the calibration of language models for question answering** \
*Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig* \
TACL 2021 [[Paper](https://arxiv.org/abs/2012.00955)]

**Teaching models to express their uncertainty in words** \
*Stephanie Lin, Jacob Hilton, Owain Evans* \
TMLR 2022 [[Paper](https://arxiv.org/abs/2205.14334)]

**On Hallucination and Predictive Uncertainty in Conditional Language Generation** \
*Yijun Xiao, William Yang Wang* \
EACL 2021 [[Paper]()]

**Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models** \
*Kaitlyn Zhou, Dan Jurafsky, Tatsunori Hashimoto* \
Feb 2023 [[Paper](https://arxiv.org/abs/2302.13439)]

**Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution Data** \
*Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao, Chao Zhang* \
EMNLP 2020  [[Paper](https://aclanthology.org/2020.emnlp-main.102/)]

**Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis** \
EMNLP Findings 2022 [[Paper](https://aclanthology.org/2022.findings-emnlp.538/)]

**Know What You Don’t Know: Unanswerable Questions for SQuAD** \
*Pranav Rajpurkar, Robin Jia, Percy Liang* \
ACL 2018 [[Paper](https://aclanthology.org/P18-2124/)]

**Calibration, Entropy Rates, and Memory in Language Models** \
*Mark Braverman, Xinyi Chen, Sham M. Kakade, Karthik Narasimhan, Cyril Zhang, Yi Zhang* \
ICML 2020 [[Paper](https://arxiv.org/abs/1906.05664)]

**A Close Look into the Calibration of Pre-trained Language Models** \
*Yangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu, Heng Ji* \
Otc 2022 [[Paper](https://arxiv.org/abs/2211.00151)]



## Better Utilization of LLMs


## Enhanced Model Capabilities
### Training & Inference

### Fine-tuning

### Reinforcement Learning


## Large Language Model for Fact-checking

**Language Models as Fact Checkers?**
**ReAct: Synergizing Reasoning and Acting in Language Models**
*Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao*
10 Mar 2023 [[Paper](https://arxiv.org/abs/2210.03629)]

**STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning**
*Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah D. Goodman*
20 May 2022 [[Paper](https://arxiv.org/abs/2203.14465)]

**Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback**
*Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao*
8 Mar 2023  [[Paper](https://arxiv.org/abs/2302.12813)]

**Faithful Reasoning Using Large Language Models**
30 Aug 2022 [[Paper](https://arxiv.org/abs/2208.14271)]

**Zero-shot fact verification by claim generation**
*Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang Wang*
31 May 2021 [[Paper](https://arxiv.org/abs/2105.14682)]

## Fact-checking for Large Language Models

**SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models**
*Potsawee Manakul, Adian Liusie, Mark J. F. Gales*
15 Mar 2023 [[Paper](https://arxiv.org/abs/2303.08896)]

**Rethinking with Retrieval: Faithful Large Language Model Inference**
*Hangfeng He, Hongming Zhang, Dan Roth*
31 Dec 2022 [[Paper](https://arxiv.org/abs/2301.00303)]

**Reflexion: an autonomous agent with dynamic memory and self-reflection**
*Noah Shinn, Beck Labash, Ashwin Gopinath*
20 Mar 2023 [[Paper](https://arxiv.org/abs/2303.11366)]

**Editing factual knowledge in language models**
*Nicola De Cao, Wilker Aziz, Ivan Titov*

**P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts**
*Benjamin Newman, Prafulla Kumar Choubey, Nazneen Rajani*
ICLR2022 [[Paper](https://openreview.net/pdf?id=DhzIU48OcZh)]

**Locating and Editing Factual Associations in GPT**
*Kevin Meng, David Bau, Alex J Andonian, Yonatan Belinkov*
NeurIPS2022 [[Paper](https://openreview.net/forum?id=-h6WAS6eE4)]

**Understanding Finetuning for Factual Knowledge Extraction from Language Models**
*Mehran Kazemi, Sid Mittal, Deepak Ramachandran*
26 Jan 2023 [[Paper](Qingxiu Dong, Damai Dai, Yifan Song, Jingjing Xu, Zhifang Sui, Lei Li)]

**Calibrating Factual Knowledge in Pretrained Language Models**
*Qingxiu Dong, Damai Dai, Yifan Song, Jingjing Xu, Zhifang Sui, Lei Li*
EMNLP 2022 [[Paper](https://aclanthology.org/2022.findings-emnlp.438/)]
## Fact-checking

**Toward Automated Factchecking: Developing an Annotation Schema and Benchmark for Consistent Automated Claim Detection**
*Lev Konstantinovskiy, Oliver Price, Mevan Babakar, Arkaitz Zubiaga*
17 Aug 2020 [[Paper](https://arxiv.org/abs/1809.08193)]

**Fully automated fact checking using external sources**
*Nicola De Cao, Wilker Aziz, Ivan Titov*
8 Sep 2021  [[Paper](https://arxiv.org/abs/2104.08164)]


## Generation


**Joint Retrieval and Generation Training for Grounded Text Generation**

**RetGen: A Joint Framework for Retrieval and Grounded Text Generation Modeling**

**Retrieval-Augmented Response Generation for Knowledge-Grounded Conversation in the Wild**

**Grounding in social media: An approach to building a chit-chat dialogue model**

**Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog**

**PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling**

**Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation**
*Understanding and Improving the Exemplar-based Generation for Open-domain Conversation*


**Webgpt: Browser-assisted question-answering with human feedback**
*Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, John Schulman*
1 Jun 2022 [[Paper](https://arxiv.org/abs/2112.09332)] \
**MedGPT: Medical concept prediction from clinical narratives**
*Zeljko Kraljevic, Anthony Shek, Daniel Bean, Rebecca Bendayan, James Teo, Richard Dobson*

**BloombergGPT: A Large Language Model for Finance**
*Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, Gideon Mann*
30 Mar 2023 [[Paper](https://arxiv.org/abs/2303.17564)]

**ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge**
*Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, Zhang You*
24 Mar 2023  [[Paper](https://arxiv.org/abs/2303.14070)]

**There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning**









